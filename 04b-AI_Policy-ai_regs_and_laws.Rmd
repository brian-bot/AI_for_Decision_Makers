```{r, include = FALSE}
ottrpal::set_knitr_image_path()
```

# Legal Regulations Around AI Use

Because generative AI is a fairly new technology for most fields, the regulations and laws surrounding its use are in flux and changing rapidly. A provisional deal on one of the first major set of AI regulations was announced by the EU government on Friday, December 8, 2023 (the [AI Act](https://artificialintelligenceact.eu/documents/)). These rules will apply to AI regulation and use within the 27-member EU bloc, as well as to foreign companies that operate within the EU, making it likely EU AI Act will guide regulations around the globe.

Countries outside of the EU are drafting their own laws and standards surrounding AI use, so you will need to do some research on what it and is not allowed in your local area.

<<add resources for people to look up their local regulations>>

## The EU AI Act

According to EU policymakers involved in writing the AI Act, the goal of the Act is to regulate AI in order to limit its capacity to cause harm. The political agreement covers the use of AI in biometric surveillance (such as facial recognition), as well as guidance on regulations for LLMs. The EU AI Act divides AI-based products into levels based on how much risk each product might pose to things like data privacy and protection. Higher-risk products with a greater capacity to cause harm face more stringent rules and regulations.

Final details are still being worked out, but we do know several important aspects of this Act.

1. All content generated by AI must be clearly identified.  

1. Foundational models like GPT as well as general purpose AI systems (GPAI) must create technical documentation and detailed summaries about the training data before they can be released on the market.

1. **High-risk AI systems** must undergo mandatory rights impact and mitigation assessments. Developers will also have to conduct model evaluations, assess and track possible cybersecurity risks, and report serious incidents and breaches to the European Commission.

1. **Open-source software** is excluded from regulations, with some exceptions for software that is considered a high-risk system or is a prohibited application.

1. AI software for manipulative strategies like deepfakes and automated disinformation campaigns, systems exploiting vulnerabilities, and indiscriminate scraping of facial images from the internet or security footage to create facial recognition databases are banned. Additional prohibited applications may be added later.

1. There are exceptions to the facial scraping ban that allow law enforcement and intelligence agencies to use AI applications for facial recognition purposes.

The AI Act also lays out financial penalties for companies that violate these regulations, which can be as high as 7% of a company's global revenue.

More information about the EU's AI Act can be found in these sources.
<<<ADD CITATIONS>>>
https://www.washingtonpost.com/technology/2023/12/08/ai-act-regulation-eu/

https://www.reuters.com/technology/stalled-eu-ai-act-talks-set-resume-2023-12-08/

https://www.euractiv.com/section/artificial-intelligence/news/ai-act-eu-policymakers-nail-down-rules-on-ai-models-butt-heads-on-law-enforcement/

https://www.ciodive.com/news/EU-AI-Act-penalties-guardrails-foundational-models/702192/#:~:text=The%20EU's%20proposed%20regulations%20prohibit,free%20will%20and%20using%20the
